import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten
import tensorflow as tf
import numpy as np


train_ds = keras.utils.image_dataset_from_directory(directory = 'C:/Users/divya/Desktop/Machine_Learning_Sebestian/Potato_Classfication_CNN/Potato_Dataset',
                                       labels = "inferred",
                                       label_mode = "int",
                                       batch_size = 32,
                                        image_size = (128,128)
                                       )


# Normalize
def process(image,label):
    image = tf.cast(image/255,tf.float32)
    return image,label

train_ds = train_ds.map(process)


## To create CNN Model

model = Sequential()

model.add(Conv2D(32,kernel_size = (3,3),padding = 'valid',activation = 'relu',input_shape=(128,128,3)))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = "valid"))

model.add(Conv2D(64,kernel_size = (3,3),padding = "valid",activation = "relu"))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = "valid"))

model.add(Conv2D(128,kernel_size = (3,3),padding = "valid",activation = "relu"))
model.add(MaxPooling2D(pool_size = (2,2),strides = 2,padding = "valid"))

model.add(Flatten())

model.add(Dense(128,activation = "relu"))
model.add(Dense(64,activation = "relu"))
model.add(Dense(1,activation = "sigmoid"))


model.summary()


model.compile(
    optimizer='adam',                  # Optimizer (e.g., Adam optimizer)
    loss='binary_crossentropy',        # Loss function (e.g., Binary Crossentropy for binary classification)
    metrics=['accuracy']               # Evaluation metric (e.g., Accuracy)
)


history = model.fit(train_ds,epochs=10)


model.save('Potato.keras')


model.save('Potato.h5')  # or 'model_name.h5'
