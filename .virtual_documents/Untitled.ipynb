import tensorflow as tf
import pandas as pd
from IPython.display import YouTubeVideo
import numpy
import IPython.display as display
import csv
import random
import os
tf.config.run_functions_eagerly(True)


import tensorflow as tf

# Parsing function to correctly read the features
def _parse_function(proto):
    # Define the features to extract from the TFRecord
    keys_to_features = {
        "id": tf.io.FixedLenFeature([], tf.string),  # Video ID (as string)
        "labels": tf.io.VarLenFeature(tf.int64),    # Labels (list of integers)
        "mean_rgb": tf.io.FixedLenFeature([1024], tf.float32),  # RGB features (1024 float values)
        "mean_audio": tf.io.FixedLenFeature([128], tf.float32)  # Audio features (128 float values)
    }
    
    # Parse the record using the defined features
    parsed_features = tf.io.parse_single_example(proto, keys_to_features)
    
    # Return the parsed video features, labels, and video id
    return parsed_features["id"], parsed_features["mean_rgb"], parsed_features["labels"]

# Load the TFRecord file and parse it
dataset = tf.data.TFRecordDataset("C:/Users/divya/data/yt8m/video/train0000.tfrecord")

# Apply the parsing function
dataset = dataset.map(_parse_function)

# Iterate through the dataset to check if parsing works
for video_id, video_features, labels in dataset.take(1):  # Preview 1 example
    # Convert sparse tensor to dense tensor for labels
    dense_labels = tf.sparse.to_dense(labels)
    
    # Decode the video ID from bytes to a string
    video_id_str = video_id.numpy().decode('utf-8')  # Decode the bytes to string
    
    # Print the decoded video ID, video features, and labels
    print("Video ID:", video_id_str)
    print("Video Features (mean_rgb):", video_features.numpy())
    print("Labels (Dense):", dense_labels.numpy())


import tensorflow as tf

# Load the label map (assuming the file is a simple text file with each line "label_id category_name")
def load_label_map(label_map_file):
    label_map = {}
    with open(label_map_file, mode='r', newline='', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader)  # Skip header row if there's one
        for row in reader:
            if len(row) >= 4:  # Ensure there are enough columns
                label_id = row[0]  # Index (first column)
                label_name = row[3]  # Name (fourth column)
                label_map[int(label_id)] = label_name
    return label_map

# Assuming you have the label map file path
label_map_file = "C:/Users/divya/Downloads/v.csv"
label_map = load_label_map(label_map_file)

# Parsing function to correctly read the features
def _parse_function(proto):
    keys_to_features = {
        "id": tf.io.FixedLenFeature([], tf.string),
        "labels": tf.io.VarLenFeature(tf.int64),
        "mean_rgb": tf.io.FixedLenFeature([1024], tf.float32),
        "mean_audio": tf.io.FixedLenFeature([128], tf.float32)
    }
    parsed_features = tf.io.parse_single_example(proto, keys_to_features)
    return parsed_features["id"], parsed_features["mean_rgb"], parsed_features["labels"]

# Load and parse the TFRecord
dataset = tf.data.TFRecordDataset("C:/Users/divya/data/yt8m/video/train0000.tfrecord")
dataset = dataset.map(_parse_function)

# Iterate through the dataset to preview data
for video_id, video_features, labels in dataset.take(1):
    dense_labels = tf.sparse.to_dense(labels)
    
    # Decode the video ID from bytes to string
    video_id_str = video_id.numpy().decode('utf-8')
    
    # Map the labels to category names
    category_names = [label_map[label_id] for label_id in dense_labels.numpy()]
    
    # Print the video ID, video features, and corresponding categories
    print("Video ID:", video_id_str)
    print("Video Features (mean_rgb):", video_features.numpy())
    print("Labels (Dense):", dense_labels.numpy())
    print("Category Names:", category_names)



import tensorflow as tf
import csv

# Load the label map (assuming the file is a CSV with Index and Name columns)
def load_label_map(label_map_file):
    label_map = {}
    with open(label_map_file, mode='r', newline='', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader)  # Skip header row if there's one
        for row in reader:
            if len(row) >= 4:  # Ensure there are enough columns
                label_id = row[0]  # Index (first column)
                label_name = row[3]  # Name (fourth column)
                label_map[int(label_id)] = label_name
    return label_map

# Assuming you have the label map file path
label_map_file = "C:/Users/divya/Downloads/v.csv"
label_map = load_label_map(label_map_file)

# Parsing function to correctly read the features
def _parse_function(proto):
    keys_to_features = {
        "id": tf.io.FixedLenFeature([], tf.string),
        "labels": tf.io.VarLenFeature(tf.int64),
        "mean_rgb": tf.io.FixedLenFeature([1024], tf.float32),
        "mean_audio": tf.io.FixedLenFeature([128], tf.float32)
    }
    parsed_features = tf.io.parse_single_example(proto, keys_to_features)
    return parsed_features["id"], parsed_features["mean_rgb"], parsed_features["labels"]

# Load and parse the TFRecord
dataset = tf.data.TFRecordDataset("C:/Users/divya/data/yt8m/video/train0000.tfrecord")
dataset = dataset.map(_parse_function)

# Extract videos with the label 136
target_label = 136

for video_id, video_features, labels in dataset:
    dense_labels = tf.sparse.to_dense(labels)
    if target_label in dense_labels.numpy():  # Check if label 136 exists
        video_id_str = video_id.numpy().decode('utf-8')
        category_names = [label_map[label_id] for label_id in dense_labels.numpy()]
        
        print("Video ID:", video_id_str)
        print("Video Features (mean_rgb):", video_features.numpy())
        print("Labels (Dense):", dense_labels.numpy())
        print("Category Names:", category_names)
        print("-" * 40)



# File paths
disney_file = "walt_disney_video_ids.txt"
non_disney_file = "not_walt_disney_video_ids.txt"

# Read video IDs into separate lists
disney_ids = pd.read_csv(disney_file, header=None, names=["video_id"])["video_id"].tolist()
non_disney_ids = pd.read_csv(non_disney_file, header=None, names=["video_id"])["video_id"].tolist()



# Disney class (label = 1)
disney_labels = [1] * len(disney_ids)

# Non-Disney class (label = 0)
non_disney_labels = [0] * len(non_disney_ids)


def balance_data(disney_ids, non_disney_ids):
    disney_size = len(disney_ids)
    # Randomly sample non-Disney IDs to match Disney dataset size
    sampled_non_disney_ids = random.sample(non_disney_ids, disney_size)
    return disney_ids, sampled_non_disney_ids


disney_ids, sampled_non_disney_ids = balance_data(disney_ids, non_disney_ids)


all_video_ids = disney_ids + sampled_non_disney_ids
all_labels = disney_labels + non_disney_labels


data = list(zip(all_video_ids, all_labels))


random.shuffle(data)


shuffled_video_ids, shuffled_labels = zip(*data)


def _parse_function(proto):
    keys_to_features = {
        "id": tf.io.FixedLenFeature([], tf.string),
        "labels": tf.io.VarLenFeature(tf.int64),  # Sparse tensor
        "mean_rgb": tf.io.FixedLenFeature([1024], tf.float32),  # Dense tensor
        "mean_audio": tf.io.FixedLenFeature([128], tf.float32),  # Dense tensor
    }
    parsed_features = tf.io.parse_single_example(proto, keys_to_features)

    # Convert SparseTensor fields to Dense (if necessary)
    parsed_features["labels"] = tf.sparse.to_dense(parsed_features["labels"])
    
    return parsed_features["id"], tf.convert_to_tensor(parsed_features["mean_rgb"]), tf.convert_to_tensor(parsed_features["mean_audio"])



def load_features_for_ids(video_ids, dataset_path):
    features = []
    for tfrecord_file in os.listdir(dataset_path):
        if tfrecord_file.endswith('.tfrecord'):
            dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, tfrecord_file))
            dataset = dataset.map(_parse_function)  # Use the updated _parse_function
            for video_id, mean_rgb, mean_audio in dataset:
                vid = video_id.numpy().decode('utf-8')
                if vid in video_ids:
                    features.append((vid, mean_rgb.numpy(), mean_audio.numpy()))
    return features


dataset_path = "C:/Users/divya/data/yt8m/video"
training_features = load_features_for_ids(shuffled_video_ids, dataset_path)


type(training_features)


# Separate features (mean_rgb + mean_audio) and labels
X = []
y = []

for vid, mean_rgb, mean_audio in training_features:
    X.append(numpy.concatenate([mean_rgb, mean_audio]))  # Combine RGB and audio features
    y.append(shuffled_labels[all_video_ids.index(vid)])  # Match label by video ID


X = numpy.array(X)
y = numpy.array(shuffled_labels)


y[0]


numpy.save("X_features.npy", X)  # Saves the features
numpy.save("Y_labels.npy", y)


numpy.savez("dataset.npz", X=X, Y=y)


# Load X and Y
X = numpy.load("X_features.npy")
Y = numpy.load("Y_labels.npy")


from tensorflow.keras import layers, models

# Input layer for single feature vector per video
input = layers.Input(shape=(1152,))  # Single feature vector (RGB + audio)

# Fully connected layers
x = layers.Dense(512, activation='relu')(input)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.3)(x)

x = layers.Dense(256, activation='relu')(x)
x = layers.BatchNormalization()(x)
x = layers.Dropout(0.3)(x)

# Output layer for binary classification
output = layers.Dense(2, activation='softmax')(x)

# Compile the model
model = models.Model(inputs=input, outputs=output)
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',  # Use this if `Y` is integers
    metrics=['accuracy']
)

# Model summary
model.summary()

# Train the model
model.fit(X, Y, epochs=10, batch_size=32, validation_split=0.2)




