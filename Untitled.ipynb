{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188fc630-7ecd-4ba2-8127-777fe932dc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from IPython.display import YouTubeVideo\n",
    "import numpy\n",
    "import IPython.display as display\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "080ed014-6268-4bf7-94fa-a49bed8c3d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: mpaa\n",
      "Video Features (mean_rgb): [ 0.12678516 -0.55269563  0.20355953 ... -0.1983184   0.04360372\n",
      " -0.37186164]\n",
      "Labels (Dense): [  0   1   5  69 378 597]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parsing function to correctly read the features\n",
    "def _parse_function(proto):\n",
    "    # Define the features to extract from the TFRecord\n",
    "    keys_to_features = {\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # Video ID (as string)\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64),    # Labels (list of integers)\n",
    "        \"mean_rgb\": tf.io.FixedLenFeature([1024], tf.float32),  # RGB features (1024 float values)\n",
    "        \"mean_audio\": tf.io.FixedLenFeature([128], tf.float32)  # Audio features (128 float values)\n",
    "    }\n",
    "    \n",
    "    # Parse the record using the defined features\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    \n",
    "    # Return the parsed video features, labels, and video id\n",
    "    return parsed_features[\"id\"], parsed_features[\"mean_rgb\"], parsed_features[\"labels\"]\n",
    "\n",
    "# Load the TFRecord file and parse it\n",
    "dataset = tf.data.TFRecordDataset(\"C:/Users/divya/data/yt8m/video/train0000.tfrecord\")\n",
    "\n",
    "# Apply the parsing function\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "# Iterate through the dataset to check if parsing works\n",
    "for video_id, video_features, labels in dataset.take(1):  # Preview 1 example\n",
    "    # Convert sparse tensor to dense tensor for labels\n",
    "    dense_labels = tf.sparse.to_dense(labels)\n",
    "    \n",
    "    # Decode the video ID from bytes to a string\n",
    "    video_id_str = video_id.numpy().decode('utf-8')  # Decode the bytes to string\n",
    "    \n",
    "    # Print the decoded video ID, video features, and labels\n",
    "    print(\"Video ID:\", video_id_str)\n",
    "    print(\"Video Features (mean_rgb):\", video_features.numpy())\n",
    "    print(\"Labels (Dense):\", dense_labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f086a1-5ce4-493c-a3b9-922ab5dc246c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: mpaa\n",
      "Video Features (mean_rgb): [ 0.12678516 -0.55269563  0.20355953 ... -0.1983184   0.04360372\n",
      " -0.37186164]\n",
      "Labels (Dense): [  0   1   5  69 378 597]\n",
      "Category Names: ['Game', 'Video game', 'Cartoon', 'Fighting game', 'M.U.G.E.N', 'Sailor Moon']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the label map (assuming the file is a simple text file with each line \"label_id category_name\")\n",
    "def load_label_map(label_map_file):\n",
    "    label_map = {}\n",
    "    with open(label_map_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row if there's one\n",
    "        for row in reader:\n",
    "            if len(row) >= 4:  # Ensure there are enough columns\n",
    "                label_id = row[0]  # Index (first column)\n",
    "                label_name = row[3]  # Name (fourth column)\n",
    "                label_map[int(label_id)] = label_name\n",
    "    return label_map\n",
    "\n",
    "# Assuming you have the label map file path\n",
    "label_map_file = \"C:/Users/divya/Downloads/v.csv\"\n",
    "label_map = load_label_map(label_map_file)\n",
    "\n",
    "# Parsing function to correctly read the features\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"mean_rgb\": tf.io.FixedLenFeature([1024], tf.float32),\n",
    "        \"mean_audio\": tf.io.FixedLenFeature([128], tf.float32)\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    return parsed_features[\"id\"], parsed_features[\"mean_rgb\"], parsed_features[\"labels\"]\n",
    "\n",
    "# Load and parse the TFRecord\n",
    "dataset = tf.data.TFRecordDataset(\"C:/Users/divya/data/yt8m/video/train0000.tfrecord\")\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "# Iterate through the dataset to preview data\n",
    "for video_id, video_features, labels in dataset.take(1):\n",
    "    dense_labels = tf.sparse.to_dense(labels)\n",
    "    \n",
    "    # Decode the video ID from bytes to string\n",
    "    video_id_str = video_id.numpy().decode('utf-8')\n",
    "    \n",
    "    # Map the labels to category names\n",
    "    category_names = [label_map[label_id] for label_id in dense_labels.numpy()]\n",
    "    \n",
    "    # Print the video ID, video features, and corresponding categories\n",
    "    print(\"Video ID:\", video_id_str)\n",
    "    print(\"Video Features (mean_rgb):\", video_features.numpy())\n",
    "    print(\"Labels (Dense):\", dense_labels.numpy())\n",
    "    print(\"Category Names:\", category_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a263b30a-49bd-4825-af83-a33a3c5b7843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video ID: bzaa\n",
      "Video Features (mean_rgb): [ 0.24584791  0.2460002  -0.36888653 ...  0.123099    0.07322274\n",
      " -0.5805751 ]\n",
      "Labels (Dense): [   5   16  136  647 1190 1360 1444 2143 3019]\n",
      "Category Names: ['Cartoon', 'Animation', 'The Walt Disney Company', 'Mickey Mouse', 'Minnie Mouse', 'Mouse', 'Donald Duck', 'Goofy', 'Pluto (Disney)']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "\n",
    "# Load the label map (assuming the file is a CSV with Index and Name columns)\n",
    "def load_label_map(label_map_file):\n",
    "    label_map = {}\n",
    "    with open(label_map_file, mode='r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # Skip header row if there's one\n",
    "        for row in reader:\n",
    "            if len(row) >= 4:  # Ensure there are enough columns\n",
    "                label_id = row[0]  # Index (first column)\n",
    "                label_name = row[3]  # Name (fourth column)\n",
    "                label_map[int(label_id)] = label_name\n",
    "    return label_map\n",
    "\n",
    "# Assuming you have the label map file path\n",
    "label_map_file = \"C:/Users/divya/Downloads/v.csv\"\n",
    "label_map = load_label_map(label_map_file)\n",
    "\n",
    "# Parsing function to correctly read the features\n",
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64),\n",
    "        \"mean_rgb\": tf.io.FixedLenFeature([1024], tf.float32),\n",
    "        \"mean_audio\": tf.io.FixedLenFeature([128], tf.float32)\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "    return parsed_features[\"id\"], parsed_features[\"mean_rgb\"], parsed_features[\"labels\"]\n",
    "\n",
    "# Load and parse the TFRecord\n",
    "dataset = tf.data.TFRecordDataset(\"C:/Users/divya/data/yt8m/video/train0000.tfrecord\")\n",
    "dataset = dataset.map(_parse_function)\n",
    "\n",
    "# Extract videos with the label 136\n",
    "target_label = 136\n",
    "\n",
    "for video_id, video_features, labels in dataset:\n",
    "    dense_labels = tf.sparse.to_dense(labels)\n",
    "    if target_label in dense_labels.numpy():  # Check if label 136 exists\n",
    "        video_id_str = video_id.numpy().decode('utf-8')\n",
    "        category_names = [label_map[label_id] for label_id in dense_labels.numpy()]\n",
    "        \n",
    "        print(\"Video ID:\", video_id_str)\n",
    "        print(\"Video Features (mean_rgb):\", video_features.numpy())\n",
    "        print(\"Labels (Dense):\", dense_labels.numpy())\n",
    "        print(\"Category Names:\", category_names)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "430fbc31-b8b8-4a2c-be72-1006ff8f2aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "disney_file = \"walt_disney_video_ids.txt\"\n",
    "non_disney_file = \"not_walt_disney_video_ids.txt\"\n",
    "\n",
    "# Read video IDs into separate lists\n",
    "disney_ids = pd.read_csv(disney_file, header=None, names=[\"video_id\"])[\"video_id\"].tolist()\n",
    "non_disney_ids = pd.read_csv(non_disney_file, header=None, names=[\"video_id\"])[\"video_id\"].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c094e58e-9a9c-486f-b65d-48352d9e5488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disney class (label = 1)\n",
    "disney_labels = [1] * len(disney_ids)\n",
    "\n",
    "# Non-Disney class (label = 0)\n",
    "non_disney_labels = [0] * len(non_disney_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0866728e-150e-410c-9624-38ab6451d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(disney_ids, non_disney_ids):\n",
    "    disney_size = len(disney_ids)\n",
    "    # Randomly sample non-Disney IDs to match Disney dataset size\n",
    "    sampled_non_disney_ids = random.sample(non_disney_ids, disney_size)\n",
    "    return disney_ids, sampled_non_disney_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1995ca3-1658-4a7c-92ce-9c85bfa1728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_ids, sampled_non_disney_ids = balance_data(disney_ids, non_disney_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7ff7190-b62e-42ea-9dbb-d5b8e1230543",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_video_ids = disney_ids + sampled_non_disney_ids\n",
    "all_labels = disney_labels + non_disney_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264e510b-f535-4fe4-b345-d78087e9d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(zip(all_video_ids, all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d37787-c024-4ae2-8ca5-5fa3a9f96bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b21dfc1-e04f-4778-84b8-3a877d573e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_video_ids, shuffled_labels = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad9e3335-50ef-42ff-87a1-817e0c76d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(proto):\n",
    "    keys_to_features = {\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"labels\": tf.io.VarLenFeature(tf.int64),  # Sparse tensor\n",
    "        \"mean_rgb\": tf.io.FixedLenFeature([1024], tf.float32),  # Dense tensor\n",
    "        \"mean_audio\": tf.io.FixedLenFeature([128], tf.float32),  # Dense tensor\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n",
    "\n",
    "    # Convert SparseTensor fields to Dense (if necessary)\n",
    "    parsed_features[\"labels\"] = tf.sparse.to_dense(parsed_features[\"labels\"])\n",
    "    \n",
    "    return parsed_features[\"id\"], tf.convert_to_tensor(parsed_features[\"mean_rgb\"]), tf.convert_to_tensor(parsed_features[\"mean_audio\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5961059e-78ea-43bc-a672-6230de59437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features_for_ids(video_ids, dataset_path):\n",
    "    features = []\n",
    "    for tfrecord_file in os.listdir(dataset_path):\n",
    "        if tfrecord_file.endswith('.tfrecord'):\n",
    "            dataset = tf.data.TFRecordDataset(os.path.join(dataset_path, tfrecord_file))\n",
    "            dataset = dataset.map(_parse_function)  # Use the updated _parse_function\n",
    "            for video_id, mean_rgb, mean_audio in dataset:\n",
    "                vid = video_id.numpy().decode('utf-8')\n",
    "                if vid in video_ids:\n",
    "                    features.append((vid, mean_rgb.numpy(), mean_audio.numpy()))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22972af5-3f20-4d05-b88c-a7df39404c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:258: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/divya/data/yt8m/video\"\n",
    "training_features = load_features_for_ids(shuffled_video_ids, dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92f39623-1933-4652-a4b5-c8926e050968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7e4e2bd8-ee42-423c-b673-08cc0ca1aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (mean_rgb + mean_audio) and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for vid, mean_rgb, mean_audio in training_features:\n",
    "    X.append(numpy.concatenate([mean_rgb, mean_audio]))  # Combine RGB and audio features\n",
    "    y.append(shuffled_labels[all_video_ids.index(vid)])  # Match label by video ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "be2c01f1-2ce7-4a25-a50b-5150772ef4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.array(X)\n",
    "y = numpy.array(shuffled_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6648729-8ac5-46e6-9607-a067d61ed5f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "582ea82d-5a88-4859-a03a-1957accd8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.save(\"X_features.npy\", X)  # Saves the features\n",
    "numpy.save(\"Y_labels.npy\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c86afc82-8c83-45b1-bbe8-7e77ad69f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savez(\"dataset.npz\", X=X, Y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db13b21b-c7bb-4034-bf98-5e9d28632250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X and Y\n",
    "X = numpy.load(\"X_features.npy\")\n",
    "Y = numpy.load(\"Y_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "80801c58-ba15-4ac5-9aae-09f8e6a56446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m590,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m514\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">725,250</span> (2.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m725,250\u001b[0m (2.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">723,714</span> (2.76 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m723,714\u001b[0m (2.76 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 275ms/step - accuracy: 0.5004 - loss: 0.9676 - val_accuracy: 0.5095 - val_loss: 0.7049\n",
      "Epoch 2/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 267ms/step - accuracy: 0.5777 - loss: 0.6774 - val_accuracy: 0.4985 - val_loss: 0.7126\n",
      "Epoch 3/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 278ms/step - accuracy: 0.6254 - loss: 0.6450 - val_accuracy: 0.4954 - val_loss: 0.7285\n",
      "Epoch 4/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 278ms/step - accuracy: 0.6615 - loss: 0.6097 - val_accuracy: 0.5021 - val_loss: 0.7472\n",
      "Epoch 5/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 278ms/step - accuracy: 0.6983 - loss: 0.5651 - val_accuracy: 0.4973 - val_loss: 0.7863\n",
      "Epoch 6/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 279ms/step - accuracy: 0.7428 - loss: 0.5156 - val_accuracy: 0.4968 - val_loss: 0.8422\n",
      "Epoch 7/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 276ms/step - accuracy: 0.7760 - loss: 0.4610 - val_accuracy: 0.4968 - val_loss: 0.9043\n",
      "Epoch 8/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 287ms/step - accuracy: 0.8141 - loss: 0.4011 - val_accuracy: 0.4922 - val_loss: 0.9446\n",
      "Epoch 9/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 292ms/step - accuracy: 0.8361 - loss: 0.3557 - val_accuracy: 0.5008 - val_loss: 0.9922\n",
      "Epoch 10/10\n",
      "\u001b[1m594/594\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 284ms/step - accuracy: 0.8463 - loss: 0.3379 - val_accuracy: 0.5015 - val_loss: 1.0381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x11fdca2f2d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Input layer for single feature vector per video\n",
    "input = layers.Input(shape=(1152,))  # Single feature vector (RGB + audio)\n",
    "\n",
    "# Fully connected layers\n",
    "x = layers.Dense(512, activation='relu')(input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# Output layer for binary classification\n",
    "output = layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Compile the model\n",
    "model = models.Model(inputs=input, outputs=output)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Use this if `Y` is integers\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93c25b-e045-43b0-83e0-76c06aaf1523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
